{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da964ced-5fb8-41c1-a4b4-e1979b11a4c9",
   "metadata": {},
   "source": [
    "## Build Data Mart\n",
    "#### Contributors:\n",
    "##### Tean 8: Anthony Ung, Sean Jerzewski, Gideon Kipkorir\n",
    "##### Team 9: Rohith, Sneha Dasarla\n",
    "##### Team 10: Anmol Brahmbhatt, Nikita Brahmbhatt, Satya"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd1c30e-e490-467d-9364-2ed64628e295",
   "metadata": {},
   "source": [
    "## 0. Dependencies and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f9f911a-574c-441b-9dfe-25f49783a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from enum import Enum\n",
    "import csv\n",
    "import sqlite3 as lite\n",
    "from decimal import Decimal\n",
    "from datetime import date, datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e689f6d5-f3ad-4ff1-adef-a63fc47134b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_MART_START = datetime.now()\n",
    "\n",
    "DB_HANDLES = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a86db21-1ae1-45df-b1d4-dc025971ab22",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae19336d-b000-4c95-a903-939303456b0d",
   "metadata": {},
   "source": [
    "## 1. Gather the file paths\n",
    "  \n",
    "  \n",
    "## IMPORTANT: \n",
    "#### Most of these files are untracked on GitHub. it is each team members'   \n",
    "####   &emsp; &emsp; It is each team members' individual responsibilities  \n",
    "####   &emsp; &emsp; to build the Database and CSV files for themselves using the other Jupyter notebooks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22c6f6dc-50c1-4057-a6c2-7d6f8924e8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATHS = {\n",
    "    'DB_TEAM_8' : './../0_SD_Team_8/store_team_8.db',\n",
    "    'DB_TEAM_9' : './../0_SD_Team_9/grocery_store.db',\n",
    "    'DB_TEAM_10' : './../0_SD_Team_10/grocery_team_10_v2.db',\n",
    "    'PRODUCTS_CSV' : './../2_Product_Mapping/PRODUCTS_MAPPED.csv'\n",
    "}\n",
    "\n",
    "DATA_MART_PATH = './Region_C_Data_Mart.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4e4e81f-ad92-4712-844d-8a4c78cb5b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - DB_TEAM_8 - './../0_SD_Team_8/store_team_8.db'\n",
      "OK - DB_TEAM_9 - './../0_SD_Team_9/grocery_store.db'\n",
      "OK - DB_TEAM_10 - './../0_SD_Team_10/grocery_team_10_v2.db'\n",
      "OK - PRODUCTS_CSV - './../2_Product_Mapping/PRODUCTS_MAPPED.csv'\n"
     ]
    }
   ],
   "source": [
    "ALL_FILES_OK = True\n",
    "\n",
    "for file_key in FILE_PATHS:\n",
    "    file_name = FILE_PATHS[file_key]\n",
    "    file_exists = os.path.isfile(file_name)\n",
    "    \n",
    "    if(file_exists):\n",
    "        print(f'OK - {file_key} - \\'{file_name}\\'')\n",
    "    else:\n",
    "        ALL_FILES_OK = False\n",
    "        print(f'MISSING - {file_key} - \\'{file_name}\\'')\n",
    "\n",
    "if not ALL_FILES_OK:\n",
    "    raise SystemExit('\\n' \"ERROR!\" '\\n' \"You are missing files!\" '\\n' \"Read and Follow the Cell instructions provided.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4bd9c4-e582-40ec-a9d1-9cf20dc1c08e",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1530d5-dd45-4da7-8311-4ac71017442b",
   "metadata": {},
   "source": [
    "## 2. Compile the table definitions\n",
    "- Modified the product table to also hold the cost to the store to assist some computations\n",
    "- If more tables need to be built, it is VITAL that the name of the table in the  \n",
    "    &ensp; &ensp; CREATE TABLE statement is the same name as the dictionary's key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60503c0d-cf87-4f93-bbaf-1bc4cdaf763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    TABLE_DEFINITIONS is a dict as follows:\n",
    "        Key - the name of the table in the database\n",
    "        Value - the CREATE TABLE statement for the table\n",
    "    I wrote a lot of unused table definitions that will be useful\n",
    "        in a later HW.\n",
    "'''\n",
    "TABLE_DEFINITIONS = {\n",
    "    'date' : \\\n",
    "            'CREATE TABLE date(' \\\n",
    "                    'DateKey INT, ' \\\n",
    "                    'PrettyDate TEXT, ' \\\n",
    "                    'DayNumberInMonth INT, ' \\\n",
    "                    'DayNumberInYear INT, ' \\\n",
    "                    'WeekNumberInYear INT, ' \\\n",
    "                    'MonthNum INT, ' \\\n",
    "                    'MonthTxt TEXT, ' \\\n",
    "                    'Quarter INT, ' \\\n",
    "                    'Year INT,' \\\n",
    "                    'FiscalYear INT, ' \\\n",
    "                    'isHoliday INT, ' \\\n",
    "                    'isWeekend INT, ' \\\n",
    "                    'Season TEXT' ')',\n",
    "\n",
    "    'product': \\\n",
    "            'CREATE TABLE product(' \\\n",
    "                    'ProductKey INT,' \\\n",
    "                    'sku INT,' \\\n",
    "                    'product_name TEXT, ' \\\n",
    "                    'product_class_id INT, ' \\\n",
    "                    'subcategory TEXT, ' \\\n",
    "                    'category TEXT, ' \\\n",
    "                    'department TEXT, ' \\\n",
    "                    'product_family TEXT, ' \\\n",
    "                    'size TEXT, ' \\\n",
    "                    'case_count INT, ' \\\n",
    "                    'BrandName TEXT, ' \\\n",
    "                    'Manufacturer TEXT, ' \\\n",
    "                    'Supplier TEXT, ' \\\n",
    "                    'CostToStore REAL)',\n",
    "\n",
    "    'product_metadata': \\\n",
    "            'CREATE TABLE product_metadata(' \\\n",
    "                    'ProductKey INT,' \\\n",
    "                    'sku INT,' \\\n",
    "                    'product_name TEXT, ' \\\n",
    "                    'old_type TEXT, ' \\\n",
    "                    'subcategory TEXT, ' \\\n",
    "                    'category TEXT, ' \\\n",
    "                    'department TEXT, ' \\\n",
    "                    'product_family TEXT, ' \\\n",
    "                    'meta_code INT,' \\\n",
    "                    'meta_mapped_by TEXT, ' \\\n",
    "                    'meta_reason TEXT)',\n",
    "    \n",
    "    'store' : \\\n",
    "            'CREATE TABLE store(' \\\n",
    "                    'StoreKey INT, ' \\\n",
    "                    'StoreManager TEXT, ' \\\n",
    "                    'StoreStreetAddr TEXT, ' \\\n",
    "                    'StoreTown TEXT, ' \\\n",
    "                    'StoreZipCode TEXT, ' \\\n",
    "                    'StorePhoneNumber TEXT, ' \\\n",
    "                    'StoreState TEXT' ')',\n",
    "    \n",
    "    'sales_transactions': \\\n",
    "            'CREATE TABLE sales_transactions(' \\\n",
    "                    'DateKey INT, ' \\\n",
    "                    'DailyCustomerNumber INT, ' \\\n",
    "                    'ProductKey INT, ' \\\n",
    "                    'StoreKey INT, ' \\\n",
    "                    'QuantitySold INT, ' \\\n",
    "                    'TotalDollarSales REAL, ' \\\n",
    "                    'TotalCostToStore REAL, ' \\\n",
    "                    'GrossProfit REAL)',\n",
    "\n",
    "    'sales_daily': \\\n",
    "            'CREATE TABLE sales_daily(' \\\n",
    "                    'DateKey INT, ' \\\n",
    "                    'ProductKey INT, ' \\\n",
    "                    'StoreKey INT, ' \\\n",
    "                    'QuantitySoldToday INT, ' \\\n",
    "                    'CostOfItemsSold REAL, ' \\\n",
    "                    'SalesTotal REAL, ' \\\n",
    "                    'GrossProfit REAL)',\n",
    "\n",
    "    'inventory_daily' : \\\n",
    "            'CREATE TABLE inventory_daily(' \\\n",
    "                    'DateKey INT, ' \\\n",
    "                    'ProductKey INT, ' \\\n",
    "                    'StoreKey INT, ' \\\n",
    "                    'NumAvailable INT, '\n",
    "                    'CostToStoreItem FLOAT, ' \\\n",
    "                    'CostToStore FLOAT, ' \\\n",
    "                    'NumCasesPurchasedToDate INT)', \n",
    "\n",
    "    'inventory_quarterly' : \\\n",
    "            'CREATE TABLE inventory_quarterly(' \\\n",
    "                    'ProductKey INT, ' \\\n",
    "                    'StoreKey INT, ' \\\n",
    "                    'QuarterAndYear TEXT, ' \\\n",
    "                    'Quarter INT, ' \\\n",
    "                    'Year INT, ' \\\n",
    "                    'CasesPurchasedToDate INT, ' \\\n",
    "                    'CasesPurchasedThisQuarter INT, ' \\\n",
    "                    'CasesOnHand INT, ' \\\n",
    "                    'TotalCostToStoreThisQuarter FLOAT, ' \\\n",
    "                    'TotalSoldByStoreThisQuarter FLOAT, ' \\\n",
    "                    'TotalCostToStoreThisYTD FLOAT, ' \\\n",
    "                    'TotalSoldByStoreThisYTD FLOAT)'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb792d7f-5e3e-41cc-ad5b-04b333e0c323",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be870414-a8b2-4e4a-b659-5d6cbc2b8539",
   "metadata": {},
   "source": [
    "## 3. Initialize the Database File and the Database API\n",
    "\n",
    "I originally made this Database API back in HW 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2023ba70-1bd6-4116-bc3a-65410e87527e",
   "metadata": {},
   "source": [
    "#### Note: The first cell in this block is destructive.\n",
    "#### If you need to see multiple versions of the database side-by-side, rename the db file before rerunning this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a7b51f9-54a1-4320-9e7e-f87fde3f74e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(DATA_MART_PATH):\n",
    "    os.remove(DATA_MART_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9912c16-cbb7-41fc-8553-4aac389be0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    If I try to make db_options an inner class to db, \n",
    "        I get an error saying that the class is undefined.\n",
    "'''\n",
    "class db_options(Enum):\n",
    "        DEFAULT = 0\n",
    "        RETURN_RESULTS = 1\n",
    "        PRINT_RESULTS = 2\n",
    "\n",
    "class db:\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = rf\"{name}\"\n",
    "\n",
    "    def connect(self):\n",
    "        self.con = lite.connect(self.name)\n",
    "        self.cur = self.con.cursor()\n",
    "\n",
    "    def build_table(self, name):      \n",
    "        self.execute_sql(f'DROP TABLE IF EXISTS {name}')\n",
    "        self.execute_sql(TABLE_DEFINITIONS[name])\n",
    "    \n",
    "    def execute_sql(self, sql, options=db_options.DEFAULT):\n",
    "        if (options.value & db_options.RETURN_RESULTS.value):\n",
    "            results = self.cur.execute(sql).fetchall()\n",
    "            return results\n",
    "        elif (options.value & db_options.PRINT_RESULTS.value):\n",
    "            results = self.cur.execute(sql).fetchall()\n",
    "            for row in results:\n",
    "                print(row)\n",
    "        else:\n",
    "            self.cur.execute(sql)\n",
    "\n",
    "    def execute_sql_values(self, sql, values, options=db_options.DEFAULT):\n",
    "        if (options.value & db_options.RETURN_RESULTS.value):\n",
    "            results = self.cur.execute(sql, values).fetchall()\n",
    "            return results\n",
    "        elif (options.value & db_options.PRINT_RESULTS.value):\n",
    "            results = self.cur.execute(sql, values).fetchall()\n",
    "            for row in results:\n",
    "                print(row)\n",
    "        else:\n",
    "            self.cur.execute(sql, values)\n",
    "\n",
    "\n",
    "    def commit(self):\n",
    "        self.con.commit()\n",
    "\n",
    "    def close(self):\n",
    "        self.con.commit()\n",
    "        self.con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ddd3e8e-7d2d-4a84-a888-b64b72c7d138",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_HANDLES['DB_TEAM_8'] = db(FILE_PATHS['DB_TEAM_8'])\n",
    "DB_HANDLES['DB_TEAM_9'] = db(FILE_PATHS['DB_TEAM_9'])\n",
    "DB_HANDLES['DB_TEAM_10'] = db(FILE_PATHS['DB_TEAM_10'])\n",
    "DB_HANDLES['DATA_MART'] = db(DATA_MART_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c937a99-3fde-4dd6-bd92-cfe6536338a5",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40064d55-276c-4895-b58f-84649778b97b",
   "metadata": {},
   "source": [
    "## 4. Build the Dimension Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d1a815-1e9f-4fb4-9f61-bdf01df91eef",
   "metadata": {},
   "source": [
    "#### Product Dimension\n",
    "The presence of the CSV generated by the script is checked earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e27e99a-1f6b-45c4-8be8-965cc59486ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product and Product Metadata Tables Populated\n"
     ]
    }
   ],
   "source": [
    "def build_product_table():\n",
    "    db_handle = DB_HANDLES['DATA_MART']\n",
    "    \n",
    "    with open(FILE_PATHS['PRODUCTS_CSV'], 'r') as csvfile:\n",
    "        db_handle.connect()\n",
    "\n",
    "        db_handle.build_table('product')\n",
    "        db_handle.build_table('product_metadata')\n",
    "        \n",
    "        for row in csv.DictReader(csvfile):\n",
    "            product_key = row['product_id']\n",
    "            sku = row['SKU']\n",
    "            product_name = row['Product Name']\n",
    "            product_class_id = row['product_class_id']\n",
    "            product_subcategory = row['product_subcategory']\n",
    "            product_category = row['product_category']\n",
    "            product_department = row['product_department']\n",
    "            product_family = row['product_family']\n",
    "            size = row['Size']\n",
    "            case_count = 12\n",
    "            brand_name = row['product_subcategory']\n",
    "            manufacturer = row['Manufacturer']\n",
    "            supplier = row['Supplier']\n",
    "            cost_to_store = round(float(Decimal(row['BasePrice'].strip('$'))),2)\n",
    "\n",
    "\n",
    "            old_type = row['itemType']\n",
    "            meta_code = row['meta_code']\n",
    "            meta_mapped_by = row['meta_mapped_by']\n",
    "            meta_reason = row['meta_reason']\n",
    "\n",
    "            db_handle.execute_sql_values(sql='insert into product values \\\n",
    "                                    (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)', \\\n",
    "                                 values=(product_key, sku, product_name, \\\n",
    "                                        product_class_id, product_subcategory, product_category, product_department, product_family, \\\n",
    "                                        size, case_count,\n",
    "                                        brand_name, manufacturer, supplier, cost_to_store))\n",
    "\n",
    "            db_handle.execute_sql_values(sql='insert into product_metadata values \\\n",
    "                                    (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)', \\\n",
    "                                    values=(product_key, sku, product_name, \\\n",
    "                                            old_type, product_subcategory, product_category, product_department, product_family, \\\n",
    "                                            meta_code, meta_mapped_by, meta_reason))\n",
    "        \n",
    "        \n",
    "        print('Product and Product Metadata Tables Populated')\n",
    "        db_handle.commit()\n",
    "        db_handle.close()\n",
    "\n",
    "build_product_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719d8d5c-9301-44dd-b903-1bd76abe6a3b",
   "metadata": {},
   "source": [
    "#### Store Dimension\n",
    "Code originally written by Gideon Kipkorir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8ae5449-5e01-470e-8731-1b0417216a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store Dimension Successfully Built\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"StoreKey\": 8,\n",
    "        \"StoreManager\": \"Anthony-Sean-Gideon\",\n",
    "        \"StoreStreetAddr\": \"1180 Seven Seas Dr\",\n",
    "        \"StoreTown\": \"Orlando\",\n",
    "        \"StoreZipCode\": \"32836\",\n",
    "        \"StorePhone#\": \"(407) 824-4500\",\n",
    "        \"StoreState\": \"FL\"\n",
    "    },\n",
    "    {\n",
    "        \"StoreKey\": 9,\n",
    "        \"StoreManager\": \"Rohith-Sneha\",\n",
    "        \"StoreStreetAddr\": \"201 Mullica Hill Road\",\n",
    "        \"StoreTown\": \"Glassboro\",\n",
    "        \"StoreZipCode\": \"08028\",\n",
    "        \"StorePhone#\": \"(856) 424-2222 x2500\",\n",
    "        \"StoreState\": \"NJ\"\n",
    "    },\n",
    "    {\n",
    "        \"StoreKey\": 10,\n",
    "        \"StoreManager\": \"Anmol-Nikita-Satya\",\n",
    "        \"StoreStreetAddr\": \"620 Anthony Ung Drive\",\n",
    "        \"StoreTown\": \"Miami\",\n",
    "        \"StoreZipCode\": \"33130\",\n",
    "        \"StorePhone#\": \"(856) 663-8006\",\n",
    "        \"StoreState\": \"FL\"\n",
    "    }\n",
    "]\n",
    "\n",
    "def build_store_dimension():\n",
    "    db_handle = DB_HANDLES['DATA_MART']\n",
    "    db_handle.connect()\n",
    "    db_handle.build_table('store')\n",
    "\n",
    "    for store in data:\n",
    "        db_handle.execute_sql_values(sql='insert into store values \\\n",
    "                                    (?, ?, ?, ?, ?, ?, ?)', \\\n",
    "                                    values=(store['StoreKey'], \\\n",
    "                                            store['StoreManager'], \\\n",
    "                                            store['StoreStreetAddr'], \\\n",
    "                                            store['StoreTown'], \\\n",
    "                                            store['StoreZipCode'], \\\n",
    "                                            store['StorePhone#'], \\\n",
    "                                            store['StoreState']))\n",
    "    \n",
    "    db_handle.commit()\n",
    "    db_handle.close()\n",
    "    print('Store Dimension Successfully Built')\n",
    "    \n",
    "\n",
    "build_store_dimension()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0a6e0b-0849-40b3-b63d-3ab9f1ef7b4f",
   "metadata": {},
   "source": [
    "#### Date Dimension\n",
    "Logic originally written by Sean Jerzewski  \n",
    "AU changed the dates of the equinoxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c97278fd-3a59-4bb5-9cca-dcd9d2a62b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Dimension Successfully Built\n"
     ]
    }
   ],
   "source": [
    "def build_date_dimension():\n",
    "    db_handle = DB_HANDLES['DATA_MART']\n",
    "    db_handle.connect()\n",
    "    db_handle.build_table('date')\n",
    "\n",
    "    start_date = date(2024,1,1)\n",
    "    end_date = date(2024,12,31)\n",
    "    \n",
    "    current_date = start_date\n",
    "    day_number = 1\n",
    "\n",
    "    holidays = [\"2024-01-01\", \\\n",
    "                \"2024-01-15\", \\\n",
    "                \"2024-02-19\", \\\n",
    "                \"2024-03-29\", \\\n",
    "                \"2024-05-27\", \\\n",
    "                \"2024-06-21\", \\\n",
    "                \"2024-07-04\", \\\n",
    "                \"2024-09-02\", \\\n",
    "                \"2024-10-14\", \\\n",
    "                \"2024-11-05\", \\\n",
    "                \"2024-11-11\", \\\n",
    "                \"2024-11-28\", \\\n",
    "                \"2024-12-25\"]\n",
    "    \n",
    "    spring = date(2024,3,21)\n",
    "    summer = date(2024,6,21)\n",
    "    fall = date(2024,9,21)\n",
    "    winter = date(2024,12,21)\n",
    "\n",
    "    while (current_date <= end_date):\n",
    "        DateKey = day_number\n",
    "        PrettyDate = current_date.strftime('%Y-%m-%d')\n",
    "        DayNumberInMonth = current_date.strftime('%d')\n",
    "        DayNumberInYear = day_number\n",
    "        WeekNumberInYear = current_date.strftime('%W')\n",
    "        MonthNum = current_date.strftime('%m')\n",
    "        MonthTxt = current_date.strftime('%B')\n",
    "        Quarter = (int(MonthNum) + 2) // 3\n",
    "        Year = current_date.year\n",
    "        FiscalYear = 2023 if current_date.month < 8 else 2024\n",
    "        isHoliday = 'True' if current_date.strftime('%Y-%m-%d') in holidays else 'False'\n",
    "\n",
    "        # 'False' is more typical than True\n",
    "        isWeekend = 'False' if current_date.weekday() < 5 else 'True'\n",
    "\n",
    "        if spring <= current_date < summer:\n",
    "            season = \"Spring\"\n",
    "        elif summer <= current_date < fall:\n",
    "            season = \"Summer\"\n",
    "        elif fall <= current_date < winter:\n",
    "            season = \"Fall\"\n",
    "        else:\n",
    "            season = \"Winter\"\n",
    "\n",
    "        db_handle.execute_sql_values(sql='insert into date values \\\n",
    "                                    (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)', \\\n",
    "                                    values=(DateKey, \\\n",
    "                                            PrettyDate, \\\n",
    "                                            DayNumberInMonth, \\\n",
    "                                            DayNumberInYear, \\\n",
    "                                            WeekNumberInYear, \\\n",
    "                                            MonthNum, \\\n",
    "                                            MonthTxt, \\\n",
    "                                            Quarter, \\\n",
    "                                            Year, \\\n",
    "                                            FiscalYear, \\\n",
    "                                            isHoliday, \\\n",
    "                                            isWeekend, \\\n",
    "                                            season))\n",
    "        \n",
    "        day_number += 1\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    db_handle.commit()\n",
    "    db_handle.close()\n",
    "    print('Date Dimension Successfully Built')\n",
    "\n",
    "build_date_dimension()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d94772-8090-464f-88d4-be2461afdfde",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6f571b-a056-4a7f-b307-21fcb187c539",
   "metadata": {},
   "source": [
    "## 5. Build the tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd582c67-d3e0-4521-bdcb-de149acda1bf",
   "metadata": {},
   "source": [
    "#### I use my own Database API to build the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9205f78b-c8bf-445b-a388-157f7244c6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_handle = DB_HANDLES['DATA_MART']\n",
    "db_handle.connect()\n",
    "db_handle.build_table('sales_transactions')\n",
    "db_handle.build_table('inventory_daily')\n",
    "db_handle.build_table('sales_daily')\n",
    "db_handle.build_table('inventory_quarterly')\n",
    "db_handle.commit()\n",
    "db_handle.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52ea4e9-1b74-40e7-8e1d-7f1529917b0f",
   "metadata": {},
   "source": [
    "#### Build an auxiliary lookup table in memory\n",
    "Given a fact table of size `m` and a dimension table of size `n`, I note the following about time and space complexity:\n",
    "Joins are O(m*n) whereas one lookup per row is O(m). The space requirement changes from O(1) to O(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c33d1a44-7a77-4e59-9dce-5b2477d5c133",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRODUCTS_LOOKUP = {}\n",
    "\n",
    "db_handle = DB_HANDLES['DATA_MART']\n",
    "db_handle.connect()\n",
    "\n",
    "sql = 'SELECT sku, ProductKey, CostToStore FROM product'\n",
    "results = db_handle.execute_sql(sql, options=db_options.RETURN_RESULTS)\n",
    "for row in results:\n",
    "    PRODUCTS_LOOKUP[str(row[0])] = {'ProductKey': row[1], 'CostToStore': row[2]}\n",
    "\n",
    "db_handle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d735494-2ae3-429a-84b3-328c9ace5d04",
   "metadata": {},
   "source": [
    "#### Create Utility One-Line Functions\n",
    "This was done to improve code readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "952d3ddf-da1c-42d3-9a96-204fb6f0a777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_money(amount): return round(amount, 2)\n",
    "def get_product_cost(sku): return PRODUCTS_LOOKUP[str(sku)]['CostToStore']\n",
    "def get_case_count(qty): return ((((qty+11)//12)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f17f0ff-17fd-4bfb-95c0-1caa7d98713c",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43192f2-7254-4ee3-a6d5-654ca799d359",
   "metadata": {},
   "source": [
    "## 6. Team 8's ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e12a4a-2c9a-47ad-b3d9-77b24425147b",
   "metadata": {},
   "source": [
    "#### I. Build the Data Structures Necessary to ETL from Team 8's Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bf5d70f-7f99-4ece-95c4-188b6aea64b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_KEYS = {}\n",
    "\n",
    "def build_data_structures_8():\n",
    "    start_date = date(2024,1,1)\n",
    "    end_date = date(2024,12,31)\n",
    "    current_date = start_date\n",
    "    \n",
    "    date_key = 1\n",
    "    \n",
    "    while (current_date <= end_date):\n",
    "        date_str = current_date.strftime('%Y-%m-%d')\n",
    "        DATE_KEYS[date_str] = date_key\n",
    "    \n",
    "        date_key += 1\n",
    "        current_date += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb19892-7592-4de8-9006-ceb9fd39b166",
   "metadata": {},
   "source": [
    "#### II. Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40cbcfe9-f010-4a20-8fdb-ea500444de64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_team_8_sales():\n",
    "    db_handle_old = DB_HANDLES['DB_TEAM_8']\n",
    "    db_handle_old.connect()\n",
    "    \n",
    "    sql_retrieve = 'SELECT date, sku, customer_number, COUNT(*), SUM(salesPrice )' \\\n",
    "            'FROM sales_transactions GROUP BY date, customer_number, sku'\n",
    "    \n",
    "    \n",
    "    db_handle_new = DB_HANDLES['DATA_MART']\n",
    "    db_handle_new.connect()\n",
    "    \n",
    "    sql_insert = 'INSERT INTO sales_transactions VALUES (?, ?, ?, ?, ?, ?, ?, ?)'\n",
    "    \n",
    "    num_records = 0\n",
    "\n",
    "    print(f'{datetime.now()} - Started Query')\n",
    "    results = db_handle_old.execute_sql(sql_retrieve, options=db_options.RETURN_RESULTS)\n",
    "    \n",
    "    print(f'{datetime.now()} - Started Insertions')\n",
    "    for row in results:\n",
    "        DateKey = DATE_KEYS[row[0]]\n",
    "        DailyCustomerNumber = row[2]\n",
    "        ProductKey = PRODUCTS_LOOKUP[str(row[1])]['ProductKey']\n",
    "        StoreKey = 8\n",
    "        QuantitySold = round_money(row[3])\n",
    "        TotalDollarSales = round_money(row[4])\n",
    "        TotalCostToStore = round_money((row[3] * get_product_cost(row[1])))\n",
    "        GrossProfit = round((TotalDollarSales - TotalCostToStore), 2)\n",
    "    \n",
    "        values = (DateKey, DailyCustomerNumber, ProductKey, StoreKey, \\\n",
    "                 QuantitySold, TotalDollarSales, TotalCostToStore, GrossProfit)\n",
    "    \n",
    "        num_records += 1\n",
    "        db_handle_new.execute_sql_values(sql_insert, values=values)\n",
    "    \n",
    "        if(num_records % 1000000 == 0):\n",
    "            db_handle_new.commit()\n",
    "            print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    \n",
    "    print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    db_handle_new.commit()\n",
    "    db_handle_new.close()\n",
    "    \n",
    "    db_handle_old.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cee242-d01a-4efb-9c95-88c29def3f97",
   "metadata": {},
   "source": [
    "#### III. Roll Sales Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "183e49bc-2aac-4b8c-97e1-2c99f716666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_team_8_sales_daily():\n",
    "    db_handle_old = DB_HANDLES['DB_TEAM_8']\n",
    "    db_handle_old.connect()\n",
    "    \n",
    "    sql_retrieve = 'SELECT date, sku, COUNT(*), SUM(salesPrice )' \\\n",
    "                    'FROM sales_transactions ' \\\n",
    "                    'GROUP BY date, sku'\n",
    "    \n",
    "    \n",
    "    db_handle_new = DB_HANDLES['DATA_MART']\n",
    "    db_handle_new.connect()\n",
    "    \n",
    "    sql_insert = 'INSERT INTO sales_daily VALUES (?, ?, ?, ?, ?, ?, ?)'\n",
    "    \n",
    "    num_records = 0\n",
    "\n",
    "    print(f'{datetime.now()} - Started Query')\n",
    "    results = db_handle_old.execute_sql(sql_retrieve, options=db_options.RETURN_RESULTS)\n",
    "    \n",
    "    print(f'{datetime.now()} - Started Insertions')\n",
    "    for row in results:\n",
    "        DateKey = DATE_KEYS[row[0]]\n",
    "        ProductKey = PRODUCTS_LOOKUP[str(row[1])]['ProductKey']\n",
    "        StoreKey = 8\n",
    "        QuantitySold = row[2]\n",
    "        TotalDollarSales = round_money(row[3])\n",
    "        TotalCostToStore = round_money((row[2] * get_product_cost(row[1])))\n",
    "        GrossProfit = round_money((TotalDollarSales - TotalCostToStore))\n",
    "        \n",
    "        values = (DateKey, ProductKey, StoreKey, \\\n",
    "                 QuantitySold, TotalDollarSales, TotalCostToStore, GrossProfit)\n",
    "        \n",
    "        num_records += 1\n",
    "        db_handle_new.execute_sql_values(sql_insert, values=values)\n",
    "    \n",
    "        if(num_records % 50000 == 0):\n",
    "            db_handle_new.commit()\n",
    "            print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    \n",
    "    print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    db_handle_new.commit()\n",
    "    db_handle_new.close()\n",
    "    \n",
    "    db_handle_old.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76a9c2e-b1f2-4018-9de7-8c1c685b75b9",
   "metadata": {},
   "source": [
    "#### IV. Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8a49c86-3f90-435c-8463-eb6a29c65624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_team_8_inventory():\n",
    "    db_handle_old = DB_HANDLES['DB_TEAM_8']\n",
    "    db_handle_old.connect()\n",
    "    \n",
    "    sql_retrieve = 'SELECT sku, date, MIN(items_left), MAX(cases_ordered)' \\\n",
    "                    'FROM sales_transactions ' \\\n",
    "                    'GROUP BY date, sku;'\n",
    "\n",
    "    print(f'{datetime.now()} - Started Query')\n",
    "    results = db_handle_old.execute_sql(sql_retrieve, options=db_options.RETURN_RESULTS)\n",
    "    print(f'{datetime.now()} - Started Insertions')\n",
    "\n",
    "    db_handle_new = DB_HANDLES['DATA_MART']\n",
    "    db_handle_new.connect()\n",
    "    \n",
    "    sql_insert = 'INSERT INTO inventory_daily VALUES (?, ?, ?, ?, ?, ?, ?)'\n",
    "\n",
    "    num_records = 0\n",
    "    for row in results:\n",
    "        DateKey = DATE_KEYS[row[1]]\n",
    "        ProductKey = PRODUCTS_LOOKUP[str(row[0])]['ProductKey']\n",
    "        StoreKey = 8\n",
    "        NumAvailable = row[2]\n",
    "        CostToStoreItem = round_money((row[2]*get_product_cost(row[0])))\n",
    "        CostToStore = round_money(12*get_case_count(row[2])*get_product_cost(row[0]))\n",
    "        NumCasesPurchasedToDate = row[3]\n",
    "        \n",
    "        values = (DateKey, ProductKey, StoreKey, NumAvailable, \\\n",
    "                 CostToStoreItem, CostToStore, NumCasesPurchasedToDate)\n",
    "    \n",
    "        num_records += 1\n",
    "        db_handle_new.execute_sql_values(sql_insert, values=values)\n",
    "    \n",
    "        if(num_records % 100000 == 0):\n",
    "            db_handle_new.commit()\n",
    "            print(f'{datetime.now()} - Committed record {num_records}')\n",
    "\n",
    "    print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    db_handle_new.commit()\n",
    "    db_handle_new.close()\n",
    "    \n",
    "    db_handle_old.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225c2476-e42a-4ae5-9efa-96411d8f4ad7",
   "metadata": {},
   "source": [
    "#### V. Run\n",
    "Comment out the call to `run_8()` to verify the functionality for other ETLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ace1ef38-41b5-42df-bfa2-b7107628ff34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-30 10:39:39.207816 - Started Query\n",
      "2025-03-30 10:40:08.760618 - Started Insertions\n",
      "2025-03-30 10:40:12.497608 - Committed record 1000000\n",
      "2025-03-30 10:40:16.430363 - Committed record 2000000\n",
      "2025-03-30 10:40:19.837188 - Committed record 3000000\n",
      "2025-03-30 10:40:24.192999 - Committed record 4000000\n",
      "2025-03-30 10:40:27.837626 - Committed record 5000000\n",
      "2025-03-30 10:40:31.337902 - Committed record 6000000\n",
      "2025-03-30 10:40:34.773815 - Committed record 7000000\n",
      "2025-03-30 10:40:38.270479 - Committed record 8000000\n",
      "2025-03-30 10:40:41.860063 - Committed record 9000000\n",
      "2025-03-30 10:40:46.080682 - Committed record 10000000\n",
      "2025-03-30 10:40:50.097034 - Committed record 11000000\n",
      "2025-03-30 10:40:54.234691 - Committed record 12000000\n",
      "2025-03-30 10:40:58.030055 - Committed record 13000000\n",
      "2025-03-30 10:41:02.017002 - Committed record 14000000\n",
      "2025-03-30 10:41:06.319127 - Committed record 15000000\n",
      "2025-03-30 10:41:10.497112 - Committed record 16000000\n",
      "2025-03-30 10:41:14.479395 - Committed record 17000000\n",
      "2025-03-30 10:41:16.156836 - Committed record 17383326\n",
      "2025-03-30 10:41:17.456597 - Started Query\n",
      "2025-03-30 10:41:32.632363 - Started Insertions\n",
      "2025-03-30 10:41:32.830276 - Committed record 50000\n",
      "2025-03-30 10:41:33.047455 - Committed record 100000\n",
      "2025-03-30 10:41:33.240558 - Committed record 150000\n",
      "2025-03-30 10:41:33.457871 - Committed record 200000\n",
      "2025-03-30 10:41:33.636649 - Committed record 250000\n",
      "2025-03-30 10:41:33.838532 - Committed record 300000\n",
      "2025-03-30 10:41:34.076468 - Committed record 350000\n",
      "2025-03-30 10:41:34.266886 - Committed record 400000\n",
      "2025-03-30 10:41:34.456641 - Committed record 450000\n",
      "2025-03-30 10:41:34.650629 - Committed record 500000\n",
      "2025-03-30 10:41:35.133136 - Committed record 550000\n",
      "2025-03-30 10:41:35.324617 - Committed record 600000\n",
      "2025-03-30 10:41:35.516648 - Committed record 650000\n",
      "2025-03-30 10:41:35.703960 - Committed record 700000\n",
      "2025-03-30 10:41:35.834460 - Committed record 738900\n",
      "2025-03-30 10:41:35.878606 - Started Query\n",
      "2025-03-30 10:41:50.288026 - Started Insertions\n",
      "2025-03-30 10:41:50.728417 - Committed record 100000\n",
      "2025-03-30 10:41:51.093613 - Committed record 200000\n",
      "2025-03-30 10:41:51.423160 - Committed record 300000\n",
      "2025-03-30 10:41:51.775631 - Committed record 400000\n",
      "2025-03-30 10:41:52.118272 - Committed record 500000\n",
      "2025-03-30 10:41:52.476941 - Committed record 600000\n",
      "2025-03-30 10:41:52.849929 - Committed record 700000\n",
      "2025-03-30 10:41:52.969263 - Committed record 738900\n"
     ]
    }
   ],
   "source": [
    "def run_8():\n",
    "    build_data_structures_8()\n",
    "    etl_team_8_sales()\n",
    "    etl_team_8_sales_daily()\n",
    "    etl_team_8_inventory()\n",
    "\n",
    "run_8()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fd154f-2af4-4593-bae3-7b8c23d9103b",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed0e58a-a2e5-4c11-b825-fb34ff9b6610",
   "metadata": {},
   "source": [
    "## 7. Team 9's ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3160c460-cf0d-407a-90ff-7802684c034b",
   "metadata": {},
   "source": [
    "#### I. Build the Data Structures Necessary to ETL from Team 8's Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b99cba5f-8d65-4126-ae94-059fed635de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_KEYS = {}\n",
    "\n",
    "def build_data_structures_9():\n",
    "    start_date = date(2024,1,1)\n",
    "    end_date = date(2024,12,31)\n",
    "    current_date = start_date\n",
    "    \n",
    "    date_key = 1\n",
    "    \n",
    "    while (current_date <= end_date):\n",
    "        date_str = current_date.strftime('%Y-%m-%d')\n",
    "        DATE_KEYS[date_str] = date_key\n",
    "    \n",
    "        date_key += 1\n",
    "        current_date += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff69d8e-c129-47fb-9d47-de803834ff2e",
   "metadata": {},
   "source": [
    "#### II. Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89d78512-e076-4489-8d7c-66d247746bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_team_9_sales():\n",
    "    db_handle_old = DB_HANDLES['DB_TEAM_9']\n",
    "    db_handle_old.connect()\n",
    "    \n",
    "    sql_retrieve = 'SELECT date1, sku, customerID , COUNT(*), SUM(salePrice) ' \\\n",
    "                    'FROM transactions ' \\\n",
    "                    'GROUP BY date1, customerID , sku'\n",
    "    \n",
    "    \n",
    "    db_handle_new = DB_HANDLES['DATA_MART']\n",
    "    db_handle_new.connect()\n",
    "    \n",
    "    sql_insert = 'INSERT INTO sales_transactions VALUES (?, ?, ?, ?, ?, ?, ?, ?)'\n",
    "    \n",
    "    num_records = 0\n",
    "\n",
    "    print(f'{datetime.now()} - Started Query')\n",
    "    results = db_handle_old.execute_sql(sql_retrieve, options=db_options.RETURN_RESULTS)\n",
    "\n",
    "    print(f'{datetime.now()} - Started Insertions')\n",
    "    for row in results:\n",
    "        DateKey = DATE_KEYS[row[0]]\n",
    "        DailyCustomerNumber = row[2]\n",
    "        ProductKey = PRODUCTS_LOOKUP[str(row[1])]['ProductKey']\n",
    "        StoreKey = 9\n",
    "        QuantitySold = row[3]\n",
    "        TotalDollarSales = row[4]\n",
    "        TotalCostToStore = round_money(row[3] * PRODUCTS_LOOKUP[str(row[1])]['CostToStore'])\n",
    "        GrossProfit = round_money((TotalDollarSales - TotalCostToStore))\n",
    "\n",
    "        values = (DateKey, DailyCustomerNumber, ProductKey, StoreKey, \\\n",
    "                 QuantitySold, TotalDollarSales, TotalCostToStore, GrossProfit)\n",
    "        \n",
    "        num_records += 1\n",
    "        db_handle_new.execute_sql_values(sql_insert, values=values)\n",
    "    \n",
    "        if(num_records % 1000000 == 0):\n",
    "            db_handle_new.commit()\n",
    "            print(f'{datetime.now()} - Committed record {num_records}')\n",
    "\n",
    "    print(f'{datetime.now()} - Committed record {num_records}')\n",
    "\n",
    "    db_handle_new.commit()\n",
    "    db_handle_new.close()\n",
    "    \n",
    "    db_handle_old.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f0cb41-25ab-4f7d-941f-70481d703f43",
   "metadata": {},
   "source": [
    "#### III. Roll Sales Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f163de7-1dd5-452f-8e40-95d0571d3897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_team_9_sales_daily():\n",
    "    db_handle_old = DB_HANDLES['DB_TEAM_9']\n",
    "    db_handle_old.connect()\n",
    "    \n",
    "    sql_retrieve = 'SELECT date1, sku, COUNT(*), SUM(salePrice) ' \\\n",
    "                    'FROM transactions ' \\\n",
    "                    'GROUP BY date1, sku'\n",
    "    \n",
    "    \n",
    "    db_handle_new = DB_HANDLES['DATA_MART']\n",
    "    db_handle_new.connect()\n",
    "    \n",
    "    sql_insert = 'INSERT INTO sales_daily VALUES (?, ?, ?, ?, ?, ?, ?)'\n",
    "    \n",
    "    num_records = 0\n",
    "\n",
    "    print(f'{datetime.now()} - Started Query')\n",
    "    results = db_handle_old.execute_sql(sql_retrieve, options=db_options.RETURN_RESULTS)\n",
    "    \n",
    "    print(f'{datetime.now()} - Started Insertions')\n",
    "    for row in results:\n",
    "        DateKey = DATE_KEYS[row[0]]\n",
    "        ProductKey = PRODUCTS_LOOKUP[str(row[1])]['ProductKey']\n",
    "        StoreKey = 9\n",
    "        QuantitySold = row[2]\n",
    "        TotalDollarSales = round_money(row[3])\n",
    "        TotalCostToStore = round_money((row[2] * PRODUCTS_LOOKUP[str(row[1])]['CostToStore']))\n",
    "        GrossProfit = round_money((TotalDollarSales - TotalCostToStore))\n",
    "        \n",
    "        values = (DateKey, ProductKey, StoreKey, \\\n",
    "                 QuantitySold, TotalDollarSales, TotalCostToStore, GrossProfit)\n",
    "        \n",
    "        num_records += 1\n",
    "        db_handle_new.execute_sql_values(sql_insert, values=values)\n",
    "    \n",
    "        if(num_records % 50000 == 0):\n",
    "            db_handle_new.commit()\n",
    "            print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    \n",
    "    print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    db_handle_new.commit()\n",
    "    db_handle_new.close()\n",
    "    \n",
    "    db_handle_old.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76321406-843f-4424-9d0d-4cd005f4c1d1",
   "metadata": {},
   "source": [
    "#### IV. Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8007bc8-ce04-46ed-a24d-595b08f4c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_team_9_inventory():\n",
    "    db_handle_old = DB_HANDLES['DB_TEAM_9']\n",
    "    db_handle_old.connect()\n",
    "    \n",
    "    sql_retrieve = 'SELECT sku, date1, MIN(itemsLeft), MAX(co)' \\\n",
    "                    'FROM transactions ' \\\n",
    "                    'GROUP BY date1, sku;'\n",
    "\n",
    "    print(f'{datetime.now()} - Started Query')\n",
    "    results = db_handle_old.execute_sql(sql_retrieve, options=db_options.RETURN_RESULTS)\n",
    "    print(f'{datetime.now()} - Started Insertions')\n",
    "\n",
    "    db_handle_new = DB_HANDLES['DATA_MART']\n",
    "    db_handle_new.connect()\n",
    "    \n",
    "    sql_insert = 'INSERT INTO inventory_daily VALUES (?, ?, ?, ?, ?, ?, ?)'\n",
    "\n",
    "    num_records = 0\n",
    "    for row in results:\n",
    "        DateKey = DATE_KEYS[row[1]]\n",
    "        ProductKey = PRODUCTS_LOOKUP[str(row[0])]['ProductKey']\n",
    "        StoreKey = 8\n",
    "        NumAvailable = row[2]\n",
    "        CostToStoreItem = round_money((row[2]*get_product_cost(row[0])))\n",
    "        CostToStore = round_money(12*get_case_count(row[2])*get_product_cost(row[0]))\n",
    "        NumCasesPurchasedToDate = row[3]\n",
    "        \n",
    "        values = (DateKey, ProductKey, StoreKey, NumAvailable, \\\n",
    "                 CostToStoreItem, CostToStore, NumCasesPurchasedToDate)\n",
    "\n",
    "        num_records += 1\n",
    "        db_handle_new.execute_sql_values(sql_insert, values=values)\n",
    "    \n",
    "        if(num_records % 100000 == 0):\n",
    "            db_handle_new.commit()\n",
    "            print(f'{datetime.now()} - Committed record {num_records}')\n",
    "\n",
    "    print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    db_handle_new.commit()\n",
    "    db_handle_new.close()\n",
    "    \n",
    "    db_handle_old.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "604c6443-9333-46b3-b80d-1a987f0c840d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-30 10:41:53.066435 - Started Query\n",
      "2025-03-30 10:42:13.974345 - Started Insertions\n",
      "2025-03-30 10:42:17.455074 - Committed record 1000000\n",
      "2025-03-30 10:42:21.507888 - Committed record 2000000\n",
      "2025-03-30 10:42:25.322084 - Committed record 3000000\n",
      "2025-03-30 10:42:29.086200 - Committed record 4000000\n",
      "2025-03-30 10:42:32.698338 - Committed record 5000000\n",
      "2025-03-30 10:42:36.229669 - Committed record 6000000\n",
      "2025-03-30 10:42:39.740935 - Committed record 7000000\n",
      "2025-03-30 10:42:43.182545 - Committed record 8000000\n",
      "2025-03-30 10:42:46.312600 - Committed record 9000000\n",
      "2025-03-30 10:42:49.450930 - Committed record 10000000\n",
      "2025-03-30 10:42:52.628669 - Committed record 11000000\n",
      "2025-03-30 10:42:55.768726 - Committed record 12000000\n",
      "2025-03-30 10:42:58.866413 - Committed record 13000000\n",
      "2025-03-30 10:43:01.526314 - Committed record 13854769\n",
      "2025-03-30 10:43:02.465879 - Started Query\n",
      "2025-03-30 10:43:13.610801 - Started Insertions\n",
      "2025-03-30 10:43:13.804134 - Committed record 50000\n",
      "2025-03-30 10:43:13.989122 - Committed record 100000\n",
      "2025-03-30 10:43:14.170512 - Committed record 150000\n",
      "2025-03-30 10:43:14.368333 - Committed record 200000\n",
      "2025-03-30 10:43:14.558326 - Committed record 250000\n",
      "2025-03-30 10:43:14.745781 - Committed record 300000\n",
      "2025-03-30 10:43:14.956330 - Committed record 350000\n",
      "2025-03-30 10:43:15.138017 - Committed record 400000\n",
      "2025-03-30 10:43:15.330019 - Committed record 450000\n",
      "2025-03-30 10:43:15.525107 - Committed record 500000\n",
      "2025-03-30 10:43:15.710107 - Committed record 550000\n",
      "2025-03-30 10:43:15.888004 - Committed record 600000\n",
      "2025-03-30 10:43:16.128855 - Committed record 650000\n",
      "2025-03-30 10:43:16.312044 - Committed record 700000\n",
      "2025-03-30 10:43:16.445671 - Committed record 739827\n",
      "2025-03-30 10:43:16.494047 - Started Query\n",
      "2025-03-30 10:43:28.297269 - Started Insertions\n",
      "2025-03-30 10:43:28.675230 - Committed record 100000\n",
      "2025-03-30 10:43:29.038623 - Committed record 200000\n",
      "2025-03-30 10:43:29.387598 - Committed record 300000\n",
      "2025-03-30 10:43:29.739989 - Committed record 400000\n",
      "2025-03-30 10:43:30.102127 - Committed record 500000\n",
      "2025-03-30 10:43:30.455588 - Committed record 600000\n",
      "2025-03-30 10:43:30.806643 - Committed record 700000\n",
      "2025-03-30 10:43:30.928711 - Committed record 739827\n"
     ]
    }
   ],
   "source": [
    "def run_9():\n",
    "    build_data_structures_9()\n",
    "    etl_team_9_sales()\n",
    "    etl_team_9_sales_daily()\n",
    "    etl_team_9_inventory()\n",
    "\n",
    "run_9()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2164059b-1f72-4b2f-9551-e9e6aaa7995e",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9498233d-2d10-4c33-8e5f-eab8b1345d83",
   "metadata": {},
   "source": [
    "## 8. Team 10's ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea90fed8-b708-4e94-bd27-9927afc0a09d",
   "metadata": {},
   "source": [
    "#### I. Build the data structures necessary for Team 10's ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15a2113e-8847-4dfd-8d1b-fdc517893643",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_KEYS = {}\n",
    "\n",
    "def build_data_structures_10():\n",
    "    start_date = date(2024,1,1)\n",
    "    end_date = date(2024,12,31)\n",
    "    current_date = start_date\n",
    "    \n",
    "    date_key = 1\n",
    "    \n",
    "    while (current_date <= end_date):\n",
    "        date_str = current_date.strftime('%Y%m%d')\n",
    "        DATE_KEYS[date_str] = date_key\n",
    "    \n",
    "        date_key += 1\n",
    "        current_date += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f3ab9f-a007-4d17-b79d-6fd4a93b37b6",
   "metadata": {},
   "source": [
    "#### II. Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76f44875-7c93-4ae7-8f57-bc57efb14338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_team_10_sales():\n",
    "    db_handle_old = DB_HANDLES['DB_TEAM_10']\n",
    "    db_handle_old.connect()\n",
    "    \n",
    "    sql_retrieve = 'SELECT date, sku, customer_number, COUNT(*), SUM(salesPrice )' \\\n",
    "            'FROM sales_transactions GROUP BY date, customer_number, sku'\n",
    "    \n",
    "    \n",
    "    db_handle_new = DB_HANDLES['DATA_MART']\n",
    "    db_handle_new.connect()\n",
    "    \n",
    "    sql_insert = 'INSERT INTO sales_transactions VALUES (?, ?, ?, ?, ?, ?, ?, ?)'\n",
    "    \n",
    "    num_records = 0\n",
    "\n",
    "    print(f'{datetime.now()} - Started Query')\n",
    "    results = db_handle_old.execute_sql(sql_retrieve, options=db_options.RETURN_RESULTS)\n",
    "    \n",
    "    print(f'{datetime.now()} - Started Insertions')\n",
    "    for row in results:\n",
    "        DateKey = DATE_KEYS[row[0]]\n",
    "        DailyCustomerNumber = row[2]\n",
    "        ProductKey = PRODUCTS_LOOKUP[str(row[1])]['ProductKey']\n",
    "        StoreKey = 10\n",
    "        QuantitySold = round_money(row[3])\n",
    "        TotalDollarSales = round_money(row[4])\n",
    "        TotalCostToStore = round_money((row[3] * get_product_cost(row[1])))\n",
    "        GrossProfit = round((TotalDollarSales - TotalCostToStore), 2)\n",
    "    \n",
    "        values = (DateKey, DailyCustomerNumber, ProductKey, StoreKey, \\\n",
    "                 QuantitySold, TotalDollarSales, TotalCostToStore, GrossProfit)\n",
    "    \n",
    "        num_records += 1\n",
    "        db_handle_new.execute_sql_values(sql_insert, values=values)\n",
    "    \n",
    "        if(num_records % 1000000 == 0):\n",
    "            db_handle_new.commit()\n",
    "            print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    \n",
    "    print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    db_handle_new.commit()\n",
    "    db_handle_new.close()\n",
    "    \n",
    "    db_handle_old.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27978211-42a1-4177-b879-2d3123afa08e",
   "metadata": {},
   "source": [
    "#### III. Roll Sales Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4ca0f2d-3233-4aea-a88a-476f14985678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_team_10_sales_daily():\n",
    "    db_handle_old = DB_HANDLES['DB_TEAM_10']\n",
    "    db_handle_old.connect()\n",
    "    \n",
    "    sql_retrieve = 'SELECT date, sku, COUNT(*), SUM(salesPrice )' \\\n",
    "                    'FROM sales_transactions ' \\\n",
    "                    'GROUP BY date, sku'\n",
    "    \n",
    "    \n",
    "    db_handle_new = DB_HANDLES['DATA_MART']\n",
    "    db_handle_new.connect()\n",
    "    \n",
    "    sql_insert = 'INSERT INTO sales_daily VALUES (?, ?, ?, ?, ?, ?, ?)'\n",
    "    \n",
    "    num_records = 0\n",
    "\n",
    "    print(f'{datetime.now()} - Started Query')\n",
    "    results = db_handle_old.execute_sql(sql_retrieve, options=db_options.RETURN_RESULTS)\n",
    "    \n",
    "    print(f'{datetime.now()} - Started Insertions')\n",
    "    for row in results:\n",
    "        DateKey = DATE_KEYS[row[0]]\n",
    "        ProductKey = PRODUCTS_LOOKUP[str(row[1])]['ProductKey']\n",
    "        StoreKey = 10\n",
    "        QuantitySold = row[2]\n",
    "        TotalDollarSales = round_money(row[3])\n",
    "        TotalCostToStore = round_money((row[2] * get_product_cost(row[1])))\n",
    "        GrossProfit = round_money((TotalDollarSales - TotalCostToStore))\n",
    "        \n",
    "        values = (DateKey, ProductKey, StoreKey, \\\n",
    "                 QuantitySold, TotalDollarSales, TotalCostToStore, GrossProfit)\n",
    "        \n",
    "        num_records += 1\n",
    "        db_handle_new.execute_sql_values(sql_insert, values=values)\n",
    "    \n",
    "        if(num_records % 50000 == 0):\n",
    "            db_handle_new.commit()\n",
    "            print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    \n",
    "    print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    db_handle_new.commit()\n",
    "    db_handle_new.close()\n",
    "    \n",
    "    db_handle_old.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f408fc00-c8e2-4488-b8a6-b00f7fc4ab1e",
   "metadata": {},
   "source": [
    "#### IV. Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f31e571b-989d-4a4d-9206-9be61ebd673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_team_10_inventory():\n",
    "    db_handle_old = DB_HANDLES['DB_TEAM_10']\n",
    "    db_handle_old.connect()\n",
    "    \n",
    "    sql_retrieve = 'SELECT sku, date, MIN(items_left), MAX(cases_ordered)' \\\n",
    "                    'FROM sales_transactions ' \\\n",
    "                    'GROUP BY date, sku;'\n",
    "\n",
    "    print(f'{datetime.now()} - Started Query')\n",
    "    results = db_handle_old.execute_sql(sql_retrieve, options=db_options.RETURN_RESULTS)\n",
    "    print(f'{datetime.now()} - Started Insertions')\n",
    "\n",
    "    db_handle_new = DB_HANDLES['DATA_MART']\n",
    "    db_handle_new.connect()\n",
    "    \n",
    "    sql_insert = 'INSERT INTO inventory_daily VALUES (?, ?, ?, ?, ?, ?, ?)'\n",
    "\n",
    "    num_records = 0\n",
    "    for row in results:\n",
    "        DateKey = DATE_KEYS[row[1]]\n",
    "        ProductKey = PRODUCTS_LOOKUP[str(row[0])]['ProductKey']\n",
    "        StoreKey = 10\n",
    "        NumAvailable = row[2]\n",
    "        CostToStoreItem = round_money((row[2]*get_product_cost(row[0])))\n",
    "        CostToStore = round_money(12*get_case_count(row[2])*get_product_cost(row[0]))\n",
    "        NumCasesPurchasedToDate = row[3]\n",
    "        \n",
    "        values = (DateKey, ProductKey, StoreKey, NumAvailable, \\\n",
    "                 CostToStoreItem, CostToStore, NumCasesPurchasedToDate)\n",
    "    \n",
    "        num_records += 1\n",
    "        db_handle_new.execute_sql_values(sql_insert, values=values)\n",
    "    \n",
    "        if(num_records % 100000 == 0):\n",
    "            db_handle_new.commit()\n",
    "            print(f'{datetime.now()} - Committed record {num_records}')\n",
    "\n",
    "    print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    db_handle_new.commit()\n",
    "    db_handle_new.close()\n",
    "    \n",
    "    db_handle_old.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bccfba23-96c4-4c29-9483-2b691b4f3719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-30 10:43:31.034852 - Started Query\n",
      "2025-03-30 10:43:49.465554 - Started Insertions\n",
      "2025-03-30 10:43:52.983311 - Committed record 1000000\n",
      "2025-03-30 10:43:56.437251 - Committed record 2000000\n",
      "2025-03-30 10:43:59.895285 - Committed record 3000000\n",
      "2025-03-30 10:44:03.358557 - Committed record 4000000\n",
      "2025-03-30 10:44:06.785438 - Committed record 5000000\n",
      "2025-03-30 10:44:10.293627 - Committed record 6000000\n",
      "2025-03-30 10:44:13.755413 - Committed record 7000000\n",
      "2025-03-30 10:44:17.178091 - Committed record 8000000\n",
      "2025-03-30 10:44:20.615837 - Committed record 9000000\n",
      "2025-03-30 10:44:24.098771 - Committed record 10000000\n",
      "2025-03-30 10:44:27.574938 - Committed record 11000000\n",
      "2025-03-30 10:44:31.003418 - Committed record 12000000\n",
      "2025-03-30 10:44:34.487752 - Committed record 13000000\n",
      "2025-03-30 10:44:34.866649 - Committed record 13109316\n",
      "2025-03-30 10:44:35.662577 - Started Query\n",
      "2025-03-30 10:44:45.686457 - Started Insertions\n",
      "2025-03-30 10:44:45.906347 - Committed record 50000\n",
      "2025-03-30 10:44:46.095471 - Committed record 100000\n",
      "2025-03-30 10:44:46.288387 - Committed record 150000\n",
      "2025-03-30 10:44:46.495272 - Committed record 200000\n",
      "2025-03-30 10:44:46.684611 - Committed record 250000\n",
      "2025-03-30 10:44:46.870719 - Committed record 300000\n",
      "2025-03-30 10:44:47.080387 - Committed record 350000\n",
      "2025-03-30 10:44:47.270598 - Committed record 400000\n",
      "2025-03-30 10:44:47.466068 - Committed record 450000\n",
      "2025-03-30 10:44:47.658239 - Committed record 500000\n",
      "2025-03-30 10:44:47.859657 - Committed record 550000\n",
      "2025-03-30 10:44:48.046705 - Committed record 600000\n",
      "2025-03-30 10:44:48.246681 - Committed record 650000\n",
      "2025-03-30 10:44:48.439318 - Committed record 700000\n",
      "2025-03-30 10:44:48.588927 - Committed record 739749\n",
      "2025-03-30 10:44:48.638438 - Started Query\n",
      "2025-03-30 10:44:59.072415 - Started Insertions\n",
      "2025-03-30 10:44:59.451219 - Committed record 100000\n",
      "2025-03-30 10:44:59.809810 - Committed record 200000\n",
      "2025-03-30 10:45:00.163609 - Committed record 300000\n",
      "2025-03-30 10:45:00.527930 - Committed record 400000\n",
      "2025-03-30 10:45:00.889354 - Committed record 500000\n",
      "2025-03-30 10:45:01.234042 - Committed record 600000\n",
      "2025-03-30 10:45:01.606969 - Committed record 700000\n",
      "2025-03-30 10:45:01.729232 - Committed record 739749\n"
     ]
    }
   ],
   "source": [
    "def run_10():\n",
    "    build_data_structures_10()\n",
    "    etl_team_10_sales()\n",
    "    etl_team_10_sales_daily()\n",
    "    etl_team_10_inventory()\n",
    "\n",
    "run_10()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45b246c-2f62-4ba4-a007-200e4a62e2fd",
   "metadata": {},
   "source": [
    "## 9 - Generate Quarterly Snapshots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa104b3-11c4-456b-a907-49874e8a8224",
   "metadata": {},
   "source": [
    "Conceptual hurdles identified\n",
    "1. We need to do aggregation by quarter, which suggests a JOIN between the `inventory_daily` and the `date` tables\n",
    "2. We need the last inventory fact for each (Store, Date, Product) tuple  \n",
    "    &emsp; &emsp; for each tuple's `CasesOnHand` and `CasesPurchasedToDate`  \n",
    "    &emsp; &emsp; and these are non-additive.  \n",
    "    &emsp; &emsp; Some (Store, Date, Product) keys may not have an Inventory fact associated with them  \n",
    "    &emsp; &emsp; because they sold 0 and we need to LEFT-JOIN multiple tables  \n",
    "    &emsp; &emsp; and do a full table scan of each table at least once for each missing (Store, Date, Product) tuple.  \n",
    "4. We need to aggregate by quarter to generate the following:  \n",
    "    &emsp; &emsp; (1) Total costs and Counts sold by the store in the current quarter  \n",
    "    &emsp; &emsp; (2) Total costs and counts sold by the store YTD.  \n",
    "    &emsp; &emsp; Generating (2) involves a self-JOIN on already-aggregated data (which warrants the use of a CTE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1efab919-26fb-4542-b66b-8811cc32c711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_date_mapping_tables():\n",
    "    db_8 = DB_HANDLES['DB_TEAM_8']\n",
    "    db_9 = DB_HANDLES['DB_TEAM_9']\n",
    "    db_10 = DB_HANDLES['DB_TEAM_10']\n",
    "\n",
    "    db_handles = [db_8, db_9, db_10]\n",
    "\n",
    "    start_date = date(2024, 1, 1)\n",
    "    end_date = date(2024, 12, 31)\n",
    "\n",
    "    current_date = start_date\n",
    "\n",
    "    sql_table_creation = '''\n",
    "                            CREATE TABLE date(\n",
    "                                date INT, \n",
    "                                quarter INT\n",
    "                            )\n",
    "                        '''\n",
    "    sql_insert = 'INSERT INTO date VALUES (?, ?)'\n",
    "    \n",
    "    for db in db_handles:\n",
    "        db.connect()\n",
    "        db.execute_sql('DROP TABLE IF EXISTS date')\n",
    "        db.execute_sql(sql_table_creation)\n",
    "\n",
    "    while(current_date <= end_date):\n",
    "        values_fmt_1 = (current_date.strftime('%Y-%m-%d'), ((current_date.month + 2)//3))\n",
    "        values_fmt_2 = (current_date.strftime('%Y%m%d'), ((current_date.month + 2)//3))\n",
    "\n",
    "        db_8.execute_sql_values(sql_insert, values_fmt_1)\n",
    "        db_9.execute_sql_values(sql_insert, values_fmt_1)\n",
    "        db_10.execute_sql_values(sql_insert, values_fmt_2)\n",
    "        \n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    for db in db_handles:\n",
    "        db.commit()\n",
    "        db.close()\n",
    "    \n",
    "build_date_mapping_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28f36b38-eabf-4c44-aae8-e4ea5afa42be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-30 10:45:01.910482 - Started Query 1\n",
      "2025-03-30 10:45:21.417070 - Finished Query 1\n",
      "2025-03-30 10:45:21.433723 - Started Query 2\n",
      "2025-03-30 10:45:34.183098 - Finished Query 2\n",
      "2025-03-30 10:45:34.202216 - Committed record 8300\n"
     ]
    }
   ],
   "source": [
    "def etl_team_8_quarterly():\n",
    "    db_handle_old = DB_HANDLES['DB_TEAM_8']\n",
    "    db_handle_old.connect()\n",
    "    \n",
    "    sql_retrieve_1 =  '''\n",
    "                        WITH quarterly_inventory AS (\n",
    "                            SELECT sku, d.date, d.quarter, \n",
    "                                FIRST_VALUE(items_left) OVER \n",
    "                                    (PARTITION BY sku, quarter ORDER BY sku ASC, d.quarter ASC, d.date DESC, items_left ASC)\n",
    "                                    AS items_left, \n",
    "                                FIRST_VALUE(cases_ordered) OVER \n",
    "                                    (PARTITION BY sku, quarter ORDER BY sku ASC, d.quarter ASC, d.date DESC, items_left ASC)\n",
    "                                    AS cases_ordered\n",
    "                            FROM sales_transactions AS st\n",
    "                            JOIN date AS d USING (date)\n",
    "                            GROUP BY sku, d.date\n",
    "                            ORDER BY sku ASC, d.date DESC, items_left DESC\n",
    "                        )\n",
    "                        SELECT sku, quarter, items_left, cases_ordered, \n",
    "                                COALESCE(\n",
    "                                    (LAG(cases_ordered, 1) OVER (PARTITION BY sku ORDER BY quarter ASC))\n",
    "                                    ,0)\n",
    "                        FROM quarterly_inventory\n",
    "                        GROUP BY sku, quarter\n",
    "                    '''\n",
    "\n",
    "    print(f'{datetime.now()} - Started Query 1')\n",
    "    results = db_handle_old.execute_sql(sql_retrieve_1, options=db_options.RETURN_RESULTS)\n",
    "    print(f'{datetime.now()} - Finished Query 1')\n",
    "\n",
    "    inventory_records = {}\n",
    "\n",
    "    for row in results:\n",
    "\n",
    "        ProductKey = PRODUCTS_LOOKUP[str(row[0])]['ProductKey']\n",
    "        StoreKey = 8\n",
    "        QuarterAndYear = f'Q{row[1]} 2024'\n",
    "        Quarter = row[1]\n",
    "        Year = 2024\n",
    "\n",
    "        CasesPurchasedToDate = row[3]\n",
    "        CasesPurchasedThisQuarter = (row[3] - row[4])\n",
    "        CasesOnHand = (row[2] // 12)\n",
    "\n",
    "        TotalCostToStoreThisQuarter = round_money(12*CasesPurchasedThisQuarter * get_product_cost(row[0]))        \n",
    "        TotalCostToStoreThisYTD = round_money(12*CasesPurchasedToDate * get_product_cost(row[0]))\n",
    "\n",
    "        key = f'{ProductKey}|{Quarter}'\n",
    "        \n",
    "        inventory_records[key] = {\n",
    "            'ProductKey': ProductKey,\n",
    "            'StoreKey': StoreKey,\n",
    "            'QuarterAndYear': QuarterAndYear,\n",
    "            'Quarter': Quarter,\n",
    "            'Year': Year,\n",
    "            'CasesPurchasedToDate': CasesPurchasedToDate,\n",
    "            'CasesPurchasedThisQuarter': CasesPurchasedThisQuarter,\n",
    "            'CasesOnHand': CasesOnHand,\n",
    "            'TotalCostToStoreThisQuarter': TotalCostToStoreThisQuarter,\n",
    "            'TotalCostToStoreThisYTD': TotalCostToStoreThisYTD\n",
    "        }\n",
    "\n",
    "\n",
    "    sql_retrieve_2 =    '''\n",
    "                            WITH quarterly_sales AS (\n",
    "                                SELECT sku, quarter, COUNT(*) AS current_quarter_count\n",
    "                                FROM sales_transactions\n",
    "                                JOIN date USING (date)\n",
    "                                GROUP BY sku, quarter\n",
    "                                ORDER BY sku, quarter ASC\n",
    "                            )\n",
    "                            SELECT sku, quarter, current_quarter_count,\n",
    "                                SUM(current_quarter_count) \n",
    "                                    OVER (PARTITION BY sku ORDER BY quarter ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS ytd_sales\n",
    "                            FROM quarterly_sales\n",
    "                            ORDER BY sku, quarter;\n",
    "                        '''\n",
    "\n",
    "    print(f'{datetime.now()} - Started Query 2')\n",
    "    results = db_handle_old.execute_sql(sql_retrieve_2, options=db_options.RETURN_RESULTS)\n",
    "    print(f'{datetime.now()} - Finished Query 2')\n",
    "\n",
    "    for row in results:\n",
    "\n",
    "        ProductKey = PRODUCTS_LOOKUP[str(row[0])]['ProductKey']\n",
    "        \n",
    "        key = f'{ProductKey}|{row[1]}'\n",
    "\n",
    "        inventory_records[key]['TotalSoldByStoreThisQuarter'] = row[2]\n",
    "        inventory_records[key]['TotalSoldByStoreThisYTD'] = row[3]\n",
    "\n",
    "\n",
    "    db_handle_new = DB_HANDLES['DATA_MART']\n",
    "    db_handle_new.connect()\n",
    "    \n",
    "    sql_insert = 'INSERT INTO inventory_quarterly VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)'\n",
    "    num_records = 0\n",
    "    for key in inventory_records:\n",
    "        values = (inventory_records[key]['ProductKey'],\n",
    "                  inventory_records[key]['StoreKey'],\n",
    "                  inventory_records[key]['QuarterAndYear'],\n",
    "                  inventory_records[key]['Quarter'],\n",
    "                  inventory_records[key]['Year'],\n",
    "                  inventory_records[key]['CasesPurchasedToDate'],\n",
    "                  inventory_records[key]['CasesPurchasedThisQuarter'],\n",
    "                  inventory_records[key]['CasesOnHand'],\n",
    "                  inventory_records[key]['TotalCostToStoreThisQuarter'],\n",
    "                  inventory_records[key]['TotalSoldByStoreThisQuarter'],\n",
    "                  inventory_records[key]['TotalCostToStoreThisYTD'],\n",
    "                  inventory_records[key]['TotalSoldByStoreThisYTD']\n",
    "        )\n",
    "\n",
    "        num_records += 1\n",
    "        db_handle_new.execute_sql_values(sql_insert, values=values)\n",
    "\n",
    "    \n",
    "    print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    db_handle_new.commit()\n",
    "    db_handle_new.close()\n",
    "    \n",
    "    db_handle_old.close()\n",
    "\n",
    "build_data_structures_8()\n",
    "etl_team_8_quarterly()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "827b9c69-0e74-4f8e-9f3d-de14f8965945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-30 10:45:34.229915 - Started Query 1\n",
      "2025-03-30 10:45:49.745122 - Finished Query 1\n",
      "2025-03-30 10:45:49.764548 - Started Query 2\n",
      "2025-03-30 10:45:59.529521 - Finished Query 2\n",
      "2025-03-30 10:45:59.559205 - Committed record 8300\n"
     ]
    }
   ],
   "source": [
    "def etl_team_9_quarterly():\n",
    "    db_handle_old = DB_HANDLES['DB_TEAM_9']\n",
    "    db_handle_old.connect()\n",
    "    \n",
    "    sql_retrieve_1 =  '''\n",
    "                        WITH quarterly_inventory AS (\n",
    "                            SELECT sku, d.date, d.quarter, \n",
    "                                FIRST_VALUE(itemsLeft) OVER \n",
    "                                    (PARTITION BY sku, quarter ORDER BY sku ASC, d.quarter ASC, d.date DESC, itemsLeft ASC)\n",
    "                                    AS items_left, \n",
    "                                FIRST_VALUE(co) OVER \n",
    "                                    (PARTITION BY sku, quarter ORDER BY sku ASC, d.quarter ASC, d.date DESC, itemsLeft ASC)\n",
    "                                    AS cases_ordered\n",
    "                            FROM transactions AS t\n",
    "                            JOIN date AS d ON t.date1 = d.date\n",
    "                            GROUP BY sku, d.date\n",
    "                            ORDER BY sku ASC, d.date DESC, itemsLeft DESC\n",
    "                        )\n",
    "                        SELECT sku, quarter, items_left, cases_ordered, \n",
    "                                COALESCE(\n",
    "                                    (LAG(cases_ordered, 1) OVER (PARTITION BY sku ORDER BY quarter ASC))\n",
    "                                    ,0)\n",
    "                        FROM quarterly_inventory\n",
    "                        GROUP BY sku, quarter\n",
    "                    '''\n",
    "\n",
    "    print(f'{datetime.now()} - Started Query 1')\n",
    "    results = db_handle_old.execute_sql(sql_retrieve_1, options=db_options.RETURN_RESULTS)\n",
    "    print(f'{datetime.now()} - Finished Query 1')\n",
    "\n",
    "    inventory_records = {}\n",
    "\n",
    "    for row in results:\n",
    "\n",
    "        ProductKey = PRODUCTS_LOOKUP[str(row[0])]['ProductKey']\n",
    "        StoreKey = 9\n",
    "        QuarterAndYear = f'Q{row[1]} 2024'\n",
    "        Quarter = row[1]\n",
    "        Year = 2024\n",
    "\n",
    "        CasesPurchasedToDate = row[3]\n",
    "        CasesPurchasedThisQuarter = (row[3] - row[4])\n",
    "        CasesOnHand = (row[2] // 12)\n",
    "\n",
    "        TotalCostToStoreThisQuarter = round_money(12*CasesPurchasedThisQuarter * get_product_cost(row[0]))        \n",
    "        TotalCostToStoreThisYTD = round_money(12*CasesPurchasedToDate * get_product_cost(row[0]))\n",
    "\n",
    "        key = f'{ProductKey}|{Quarter}'\n",
    "        \n",
    "        inventory_records[key] = {\n",
    "            'ProductKey': ProductKey,\n",
    "            'StoreKey': StoreKey,\n",
    "            'QuarterAndYear': QuarterAndYear,\n",
    "            'Quarter': Quarter,\n",
    "            'Year': Year,\n",
    "            'CasesPurchasedToDate': CasesPurchasedToDate,\n",
    "            'CasesPurchasedThisQuarter': CasesPurchasedThisQuarter,\n",
    "            'CasesOnHand': CasesOnHand,\n",
    "            'TotalCostToStoreThisQuarter': TotalCostToStoreThisQuarter,\n",
    "            'TotalCostToStoreThisYTD': TotalCostToStoreThisYTD\n",
    "        }\n",
    "\n",
    "\n",
    "    sql_retrieve_2 =    '''\n",
    "                            WITH quarterly_sales AS (\n",
    "                                SELECT sku, quarter, COUNT(*) AS current_quarter_count\n",
    "                                FROM transactions AS t\n",
    "                                JOIN date AS d ON t.date1 = d.date\n",
    "                                GROUP BY sku, quarter\n",
    "                                ORDER BY sku, quarter ASC\n",
    "                            )\n",
    "                            SELECT sku, quarter, current_quarter_count,\n",
    "                                SUM(current_quarter_count) \n",
    "                                    OVER (PARTITION BY sku ORDER BY quarter ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS ytd_sales\n",
    "                            FROM quarterly_sales\n",
    "                            ORDER BY sku, quarter;\n",
    "                        '''\n",
    "\n",
    "    print(f'{datetime.now()} - Started Query 2')\n",
    "    results = db_handle_old.execute_sql(sql_retrieve_2, options=db_options.RETURN_RESULTS)\n",
    "    print(f'{datetime.now()} - Finished Query 2')\n",
    "\n",
    "    for row in results:\n",
    "\n",
    "        ProductKey = PRODUCTS_LOOKUP[str(row[0])]['ProductKey']\n",
    "        \n",
    "        key = f'{ProductKey}|{row[1]}'\n",
    "\n",
    "        inventory_records[key]['TotalSoldByStoreThisQuarter'] = row[2]\n",
    "        inventory_records[key]['TotalSoldByStoreThisYTD'] = row[3]\n",
    "\n",
    "\n",
    "    db_handle_new = DB_HANDLES['DATA_MART']\n",
    "    db_handle_new.connect()\n",
    "    \n",
    "    sql_insert = 'INSERT INTO inventory_quarterly VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)'\n",
    "    num_records = 0\n",
    "    for key in inventory_records:\n",
    "        values = (inventory_records[key]['ProductKey'],\n",
    "                  inventory_records[key]['StoreKey'],\n",
    "                  inventory_records[key]['QuarterAndYear'],\n",
    "                  inventory_records[key]['Quarter'],\n",
    "                  inventory_records[key]['Year'],\n",
    "                  inventory_records[key]['CasesPurchasedToDate'],\n",
    "                  inventory_records[key]['CasesPurchasedThisQuarter'],\n",
    "                  inventory_records[key]['CasesOnHand'],\n",
    "                  inventory_records[key]['TotalCostToStoreThisQuarter'],\n",
    "                  inventory_records[key]['TotalSoldByStoreThisQuarter'],\n",
    "                  inventory_records[key]['TotalCostToStoreThisYTD'],\n",
    "                  inventory_records[key]['TotalSoldByStoreThisYTD']\n",
    "        )\n",
    "\n",
    "        num_records += 1\n",
    "        db_handle_new.execute_sql_values(sql_insert, values=values)\n",
    "\n",
    "    \n",
    "    print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    db_handle_new.commit()\n",
    "    db_handle_new.close()\n",
    "    \n",
    "    db_handle_old.close()\n",
    "\n",
    "build_data_structures_9()\n",
    "etl_team_9_quarterly()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b0113b4-e530-43ee-a306-e06032306085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-30 10:45:59.577813 - Started Query 1\n",
      "2025-03-30 10:46:10.727229 - Finished Query 1\n",
      "2025-03-30 10:46:10.743027 - Started Query 2\n",
      "2025-03-30 10:46:18.623679 - Finished Query 2\n",
      "2025-03-30 10:46:18.661734 - Committed record 8300\n"
     ]
    }
   ],
   "source": [
    "def etl_team_10_quarterly():\n",
    "    db_handle_old = DB_HANDLES['DB_TEAM_10']\n",
    "    db_handle_old.connect()\n",
    "    \n",
    "    sql_retrieve_1 =  '''\n",
    "                        WITH quarterly_inventory AS (\n",
    "                            SELECT sku, d.date, d.quarter, \n",
    "                                FIRST_VALUE(items_left) OVER \n",
    "                                    (PARTITION BY sku, quarter ORDER BY sku ASC, d.quarter ASC, d.date DESC, items_left ASC)\n",
    "                                    AS items_left, \n",
    "                                FIRST_VALUE(cases_ordered) OVER \n",
    "                                    (PARTITION BY sku, quarter ORDER BY sku ASC, d.quarter ASC, d.date DESC, items_left ASC)\n",
    "                                    AS cases_ordered\n",
    "                            FROM sales_transactions AS st\n",
    "                            JOIN date AS d USING (date)\n",
    "                            GROUP BY sku, d.date\n",
    "                            ORDER BY sku ASC, d.date DESC, items_left DESC\n",
    "                        )\n",
    "                        SELECT sku, quarter, items_left, cases_ordered, \n",
    "                                COALESCE(\n",
    "                                    (LAG(cases_ordered, 1) OVER (PARTITION BY sku ORDER BY quarter ASC))\n",
    "                                    ,0)\n",
    "                        FROM quarterly_inventory\n",
    "                        GROUP BY sku, quarter\n",
    "                    '''\n",
    "\n",
    "    print(f'{datetime.now()} - Started Query 1')\n",
    "    results = db_handle_old.execute_sql(sql_retrieve_1, options=db_options.RETURN_RESULTS)\n",
    "    print(f'{datetime.now()} - Finished Query 1')\n",
    "\n",
    "    inventory_records = {}\n",
    "\n",
    "    for row in results:\n",
    "\n",
    "        ProductKey = PRODUCTS_LOOKUP[str(row[0])]['ProductKey']\n",
    "        StoreKey = 10\n",
    "        QuarterAndYear = f'Q{row[1]} 2024'\n",
    "        Quarter = row[1]\n",
    "        Year = 2024\n",
    "\n",
    "        CasesPurchasedToDate = row[3]\n",
    "        CasesPurchasedThisQuarter = (row[3] - row[4])\n",
    "        CasesOnHand = (row[2] // 12)\n",
    "\n",
    "        TotalCostToStoreThisQuarter = round_money(12*CasesPurchasedThisQuarter * get_product_cost(row[0]))        \n",
    "        TotalCostToStoreThisYTD = round_money(12*CasesPurchasedToDate * get_product_cost(row[0]))\n",
    "\n",
    "        key = f'{ProductKey}|{Quarter}'\n",
    "        \n",
    "        inventory_records[key] = {\n",
    "            'ProductKey': ProductKey,\n",
    "            'StoreKey': StoreKey,\n",
    "            'QuarterAndYear': QuarterAndYear,\n",
    "            'Quarter': Quarter,\n",
    "            'Year': Year,\n",
    "            'CasesPurchasedToDate': CasesPurchasedToDate,\n",
    "            'CasesPurchasedThisQuarter': CasesPurchasedThisQuarter,\n",
    "            'CasesOnHand': CasesOnHand,\n",
    "            'TotalCostToStoreThisQuarter': TotalCostToStoreThisQuarter,\n",
    "            'TotalCostToStoreThisYTD': TotalCostToStoreThisYTD\n",
    "        }\n",
    "\n",
    "\n",
    "    sql_retrieve_2 =    '''\n",
    "                            WITH quarterly_sales AS (\n",
    "                                SELECT sku, quarter, COUNT(*) AS current_quarter_count\n",
    "                                FROM sales_transactions\n",
    "                                JOIN date USING (date)\n",
    "                                GROUP BY sku, quarter\n",
    "                                ORDER BY sku, quarter ASC\n",
    "                            )\n",
    "                            SELECT sku, quarter, current_quarter_count,\n",
    "                                SUM(current_quarter_count) \n",
    "                                    OVER (PARTITION BY sku ORDER BY quarter ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS ytd_sales\n",
    "                            FROM quarterly_sales\n",
    "                            ORDER BY sku, quarter;\n",
    "                        '''\n",
    "\n",
    "    print(f'{datetime.now()} - Started Query 2')\n",
    "    results = db_handle_old.execute_sql(sql_retrieve_2, options=db_options.RETURN_RESULTS)\n",
    "    print(f'{datetime.now()} - Finished Query 2')\n",
    "\n",
    "    for row in results:\n",
    "\n",
    "        ProductKey = PRODUCTS_LOOKUP[str(row[0])]['ProductKey']\n",
    "        \n",
    "        key = f'{ProductKey}|{row[1]}'\n",
    "\n",
    "        inventory_records[key]['TotalSoldByStoreThisQuarter'] = row[2]\n",
    "        inventory_records[key]['TotalSoldByStoreThisYTD'] = row[3]\n",
    "\n",
    "\n",
    "    db_handle_new = DB_HANDLES['DATA_MART']\n",
    "    db_handle_new.connect()\n",
    "    \n",
    "    sql_insert = 'INSERT INTO inventory_quarterly VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)'\n",
    "    num_records = 0\n",
    "    for key in inventory_records:\n",
    "        values = (inventory_records[key]['ProductKey'],\n",
    "                  inventory_records[key]['StoreKey'],\n",
    "                  inventory_records[key]['QuarterAndYear'],\n",
    "                  inventory_records[key]['Quarter'],\n",
    "                  inventory_records[key]['Year'],\n",
    "                  inventory_records[key]['CasesPurchasedToDate'],\n",
    "                  inventory_records[key]['CasesPurchasedThisQuarter'],\n",
    "                  inventory_records[key]['CasesOnHand'],\n",
    "                  inventory_records[key]['TotalCostToStoreThisQuarter'],\n",
    "                  inventory_records[key]['TotalSoldByStoreThisQuarter'],\n",
    "                  inventory_records[key]['TotalCostToStoreThisYTD'],\n",
    "                  inventory_records[key]['TotalSoldByStoreThisYTD']\n",
    "        )\n",
    "\n",
    "        num_records += 1\n",
    "        db_handle_new.execute_sql_values(sql_insert, values=values)\n",
    "\n",
    "    \n",
    "    print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    db_handle_new.commit()\n",
    "    db_handle_new.close()\n",
    "    \n",
    "    db_handle_old.close()\n",
    "\n",
    "build_data_structures_10()\n",
    "etl_team_10_quarterly()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e52343-009e-488d-ac8e-eb53553677ad",
   "metadata": {},
   "source": [
    "#### Duration of the batch job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b686f452-92e2-434d-8095-0dcf0c9a9d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START: 2025-03-30 10:39:38.538135\n",
      "END: 2025-03-30 10:46:18.676874\n",
      "This batch job took 0:06:40.138739\n"
     ]
    }
   ],
   "source": [
    "DATA_MART_END = datetime.now()\n",
    "DATA_MART_DURATION = DATA_MART_END - DATA_MART_START\n",
    "\n",
    "print(f'START: {DATA_MART_START}')\n",
    "print(f'END: {DATA_MART_END}')\n",
    "print(f'This batch job took {DATA_MART_DURATION}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
