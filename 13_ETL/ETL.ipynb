{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73eac375-54d3-4f82-aabe-6b56d56940f0",
   "metadata": {},
   "source": [
    "## ETL\n",
    "#### Contributors:\n",
    "##### Tean 8: Anthony Ung, Sean Jerzewski, Gideon Kipkorir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09205af-7f77-40d7-b4a1-4c13990322f9",
   "metadata": {},
   "source": [
    "## 0. Dependencies and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15e05404-58d9-42bf-8f8d-e1558aa70894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from enum import Enum\n",
    "import csv\n",
    "import sqlite3 as lite\n",
    "from decimal import Decimal\n",
    "from datetime import date, datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c308e9-a67a-4e09-a319-0b5f7f4f63c7",
   "metadata": {},
   "source": [
    "## 1. Gather the file paths\n",
    "  \n",
    "  \n",
    "## IMPORTANT: \n",
    "#### Most of these files are untracked on GitHub. it is each team members'   \n",
    "####   &emsp; &emsp; It is each team members' individual responsibilities  \n",
    "####   &emsp; &emsp; to build the Database and CSV files for themselves using the other Jupyter notebooks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a593e6d0-bd77-46c5-ba9f-8e86de14e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATHS = {\n",
    "    'DB_TEAM_8' : './../12_Run_Transactions/store.db',\n",
    "    'DATA_MART' : './../01_Source_DBs/Region_C_Data_Mart.db'\n",
    "}\n",
    "\n",
    "DB_HANDLES = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fd4a4d4-d350-4189-8ea4-ae4a6fe38967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - DB_TEAM_8 - './../12_Run_Transactions/store.db'\n",
      "OK - DATA_MART_PATH - './../01_Source_DBs/Region_C_Data_Mart.db'\n"
     ]
    }
   ],
   "source": [
    "ALL_FILES_OK = True\n",
    "\n",
    "for file_key in FILE_PATHS:\n",
    "    file_name = FILE_PATHS[file_key]\n",
    "    file_exists = os.path.isfile(file_name)\n",
    "    \n",
    "    if(file_exists):\n",
    "        print(f'OK - {file_key} - \\'{file_name}\\'')\n",
    "    else:\n",
    "        ALL_FILES_OK = False\n",
    "        print(f'MISSING - {file_key} - \\'{file_name}\\'')\n",
    "\n",
    "if not ALL_FILES_OK:\n",
    "    raise SystemExit('\\n' \"ERROR!\" '\\n' \"You are missing files!\" '\\n' \"Read and Follow the Cell instructions provided.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb14c8f9-bc9c-449b-81ba-3ca169f98b4f",
   "metadata": {},
   "source": [
    "## 2. Initialize the Database File and the Database API\n",
    "\n",
    "I originally made this Database API back in HW 2 and developed it throughout the semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b795245-4bd2-4c49-9fc5-49a8e229443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    If I try to make db_options an inner class to db, \n",
    "        I get an error saying that the class is undefined.\n",
    "'''\n",
    "class db_options(Enum):\n",
    "        DEFAULT = 0\n",
    "        RETURN_RESULTS = 1\n",
    "        PRINT_RESULTS = 2\n",
    "\n",
    "class db:\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = rf\"{name}\"\n",
    "\n",
    "    def connect(self):\n",
    "        self.con = lite.connect(self.name)\n",
    "        self.cur = self.con.cursor()\n",
    "\n",
    "    def build_table(self, name):      \n",
    "        self.execute_sql(f'DROP TABLE IF EXISTS {name}')\n",
    "        self.execute_sql(TABLE_DEFINITIONS[name])\n",
    "    \n",
    "    def execute_sql(self, sql, options=db_options.DEFAULT):\n",
    "        if (options.value & db_options.RETURN_RESULTS.value):\n",
    "            results = self.cur.execute(sql).fetchall()\n",
    "            return results\n",
    "        elif (options.value & db_options.PRINT_RESULTS.value):\n",
    "            results = self.cur.execute(sql).fetchall()\n",
    "            for row in results:\n",
    "                print(row)\n",
    "        else:\n",
    "            self.cur.execute(sql)\n",
    "\n",
    "    def execute_sql_values(self, sql, values, options=db_options.DEFAULT):\n",
    "        if (options.value & db_options.RETURN_RESULTS.value):\n",
    "            results = self.cur.execute(sql, values).fetchall()\n",
    "            return results\n",
    "        elif (options.value & db_options.PRINT_RESULTS.value):\n",
    "            results = self.cur.execute(sql, values).fetchall()\n",
    "            for row in results:\n",
    "                print(row)\n",
    "        else:\n",
    "            self.cur.execute(sql, values)\n",
    "\n",
    "\n",
    "    def commit(self):\n",
    "        self.con.commit()\n",
    "\n",
    "    def close(self):\n",
    "        self.con.commit()\n",
    "        self.con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "956c1d58-b1f6-40ea-b375-50db3e5fcc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_HANDLES['DB_TEAM_8'] = db(FILE_PATHS['DB_TEAM_8'])\n",
    "DB_HANDLES['DATA_MART'] = db(FILE_PATHS['DATA_MART'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc53d65-4650-4707-a88c-69debfd45e99",
   "metadata": {},
   "source": [
    "## 4. Miscellany\n",
    "\n",
    "#### Build an auxiliary lookup table in memory\n",
    "Given a fact table of size `m` and a dimension table of size `n`, I note the following about time and space complexity:\n",
    "Joins are O(m*n) whereas one lookup per row is O(m). The space requirement changes from O(1) to O(n)\n",
    "\n",
    "#### Create Utility One-Line Functions\n",
    "This was done to improve code readability.\n",
    "\n",
    "#### Known Peculiarity\n",
    "The old `product` table and the new `products` table coexist at the same time.  \n",
    "I will keep both becuase I need the base prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38a62c29-cec3-42c6-8c53-1fe8fb5c5cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRODUCTS_LOOKUP = {}\n",
    "\n",
    "db_handle = DB_HANDLES['DATA_MART']\n",
    "db_handle.connect()\n",
    "\n",
    "sql = 'SELECT sku, ProductKey, CostToStore FROM product'\n",
    "results = db_handle.execute_sql(sql, options=db_options.RETURN_RESULTS)\n",
    "for row in results:\n",
    "    PRODUCTS_LOOKUP[str(row[0])] = {'ProductKey': row[1], 'CostToStore': row[2]}\n",
    "\n",
    "db_handle.close()\n",
    "\n",
    "def round_money(amount): return round(amount, 2)\n",
    "def get_product_cost(sku): return PRODUCTS_LOOKUP[str(sku)]['CostToStore']\n",
    "def get_case_count(qty): return ((((qty+11)//12)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7ce466-4470-40dd-a473-f06950fc02e5",
   "metadata": {},
   "source": [
    "## 5. Team 8's ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2610c44e-88a3-4282-bd83-7571493306b9",
   "metadata": {},
   "source": [
    "#### I. Build the Data Structures Necessary to ETL from Team 8's Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73219024-109d-46cb-a293-266ed4433d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_KEYS = {}\n",
    "\n",
    "def build_data_structures_8():\n",
    "    start_date = date(2024,1,1)\n",
    "    end_date = date(2025,6,30)\n",
    "    current_date = start_date\n",
    "    \n",
    "    date_key = 1\n",
    "    \n",
    "    while (current_date <= end_date):\n",
    "        date_str = current_date.strftime('%Y-%m-%d')\n",
    "        DATE_KEYS[date_str] = date_key\n",
    "    \n",
    "        date_key += 1\n",
    "        current_date += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661c61ec-b8a1-481b-bafd-de6e170cbf09",
   "metadata": {},
   "source": [
    "#### II. Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c824a29d-0cf9-4f24-8e24-4c23f1c4b121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_team_8_sales():\n",
    "    db_handle_old = DB_HANDLES['DB_TEAM_8']\n",
    "    db_handle_old.connect()\n",
    "    \n",
    "    sql_retrieve = 'SELECT date, sku, customer_number, COUNT(*), SUM(salesPrice )' \\\n",
    "            'FROM sales_transactions GROUP BY date, customer_number, sku'\n",
    "    \n",
    "    \n",
    "    db_handle_new = DB_HANDLES['DATA_MART']\n",
    "    db_handle_new.connect()\n",
    "    \n",
    "    sql_insert = 'INSERT INTO sales_transactions VALUES (?, ?, ?, ?, ?, ?, ?, ?)'\n",
    "    \n",
    "    num_records = 0\n",
    "\n",
    "    print(f'{datetime.now()} - Started Query')\n",
    "    results = db_handle_old.execute_sql(sql_retrieve, options=db_options.RETURN_RESULTS)\n",
    "    \n",
    "    print(f'{datetime.now()} - Started Insertions')\n",
    "    for row in results:\n",
    "        DateKey = DATE_KEYS[row[0]]\n",
    "        DailyCustomerNumber = row[2]\n",
    "        ProductKey = PRODUCTS_LOOKUP[str(row[1])]['ProductKey']\n",
    "        StoreKey = 8\n",
    "        QuantitySold = round_money(row[3])\n",
    "        TotalDollarSales = round_money(row[4])\n",
    "        TotalCostToStore = round_money((row[3] * get_product_cost(row[1])))\n",
    "        GrossProfit = round((TotalDollarSales - TotalCostToStore), 2)\n",
    "    \n",
    "        values = (DateKey, DailyCustomerNumber, ProductKey, StoreKey, \\\n",
    "                 QuantitySold, TotalDollarSales, TotalCostToStore, GrossProfit)\n",
    "    \n",
    "        num_records += 1\n",
    "        db_handle_new.execute_sql_values(sql_insert, values=values)\n",
    "    \n",
    "        if(num_records % 1000000 == 0):\n",
    "            db_handle_new.commit()\n",
    "            print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    \n",
    "    print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    db_handle_new.commit()\n",
    "    db_handle_new.close()\n",
    "    \n",
    "    db_handle_old.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd614bfc-4973-4a9b-bdb4-c255fe5e207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_team_8_sales_daily():\n",
    "    db_handle_old = DB_HANDLES['DB_TEAM_8']\n",
    "    db_handle_old.connect()\n",
    "    \n",
    "    sql_retrieve = 'SELECT date, sku, COUNT(*), SUM(salesPrice )' \\\n",
    "                    'FROM sales_transactions ' \\\n",
    "                    'GROUP BY date, sku'\n",
    "    \n",
    "    \n",
    "    db_handle_new = DB_HANDLES['DATA_MART']\n",
    "    db_handle_new.connect()\n",
    "    \n",
    "    sql_insert = 'INSERT INTO sales_daily VALUES (?, ?, ?, ?, ?, ?, ?)'\n",
    "    \n",
    "    num_records = 0\n",
    "\n",
    "    print(f'{datetime.now()} - Started Query')\n",
    "    results = db_handle_old.execute_sql(sql_retrieve, options=db_options.RETURN_RESULTS)\n",
    "    \n",
    "    print(f'{datetime.now()} - Started Insertions')\n",
    "    for row in results:\n",
    "        DateKey = DATE_KEYS[row[0]]\n",
    "        ProductKey = PRODUCTS_LOOKUP[str(row[1])]['ProductKey']\n",
    "        StoreKey = 8\n",
    "        QuantitySold = row[2]\n",
    "        TotalDollarSales = round_money(row[3])\n",
    "        TotalCostToStore = round_money((row[2] * get_product_cost(row[1])))\n",
    "        GrossProfit = round_money((TotalDollarSales - TotalCostToStore))\n",
    "        \n",
    "        values = (DateKey, ProductKey, StoreKey, \\\n",
    "                 QuantitySold, TotalDollarSales, TotalCostToStore, GrossProfit)\n",
    "        \n",
    "        num_records += 1\n",
    "        db_handle_new.execute_sql_values(sql_insert, values=values)\n",
    "    \n",
    "        if(num_records % 50000 == 0):\n",
    "            db_handle_new.commit()\n",
    "            print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    \n",
    "    print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    db_handle_new.commit()\n",
    "    db_handle_new.close()\n",
    "    \n",
    "    db_handle_old.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3262490a-c16b-4cbc-8bc3-5d8c0a7e2fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_team_8_inventory():\n",
    "    db_handle_old = DB_HANDLES['DB_TEAM_8']\n",
    "    db_handle_old.connect()\n",
    "    \n",
    "    sql_retrieve = 'SELECT sku, date, MIN(items_left), MAX(cases_ordered)' \\\n",
    "                    'FROM sales_transactions ' \\\n",
    "                    'GROUP BY date, sku;'\n",
    "\n",
    "    print(f'{datetime.now()} - Started Query')\n",
    "    results = db_handle_old.execute_sql(sql_retrieve, options=db_options.RETURN_RESULTS)\n",
    "    print(f'{datetime.now()} - Started Insertions')\n",
    "\n",
    "    db_handle_new = DB_HANDLES['DATA_MART']\n",
    "    db_handle_new.connect()\n",
    "    \n",
    "    sql_insert = 'INSERT INTO inventory_daily VALUES (?, ?, ?, ?, ?, ?, ?)'\n",
    "\n",
    "    num_records = 0\n",
    "    for row in results:\n",
    "        DateKey = DATE_KEYS[row[1]]\n",
    "        ProductKey = PRODUCTS_LOOKUP[str(row[0])]['ProductKey']\n",
    "        StoreKey = 8\n",
    "        NumAvailable = row[2]\n",
    "        CostToStoreItem = round_money((row[2]*get_product_cost(row[0])))\n",
    "        CostToStore = round_money(12*get_case_count(row[2])*get_product_cost(row[0]))\n",
    "        NumCasesPurchasedToDate = row[3]\n",
    "        \n",
    "        values = (DateKey, ProductKey, StoreKey, NumAvailable, \\\n",
    "                 CostToStoreItem, CostToStore, NumCasesPurchasedToDate)\n",
    "    \n",
    "        num_records += 1\n",
    "        db_handle_new.execute_sql_values(sql_insert, values=values)\n",
    "    \n",
    "        if(num_records % 100000 == 0):\n",
    "            db_handle_new.commit()\n",
    "            print(f'{datetime.now()} - Committed record {num_records}')\n",
    "\n",
    "    print(f'{datetime.now()} - Committed record {num_records}')\n",
    "    db_handle_new.commit()\n",
    "    db_handle_new.close()\n",
    "    \n",
    "    db_handle_old.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09698807-65df-4870-a93f-9a1e4b54f3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-03 22:16:50.555410 - Started Query\n",
      "2025-05-03 22:17:01.400757 - Started Insertions\n",
      "2025-05-03 22:17:04.298727 - Committed record 1000000\n",
      "2025-05-03 22:17:07.391618 - Committed record 2000000\n",
      "2025-05-03 22:17:10.334554 - Committed record 3000000\n",
      "2025-05-03 22:17:13.180986 - Committed record 4000000\n",
      "2025-05-03 22:17:16.056160 - Committed record 5000000\n",
      "2025-05-03 22:17:18.933568 - Committed record 6000000\n",
      "2025-05-03 22:17:21.921528 - Committed record 7000000\n",
      "2025-05-03 22:17:25.060614 - Committed record 8000000\n",
      "2025-05-03 22:17:26.923441 - Committed record 8599756\n",
      "2025-05-03 22:17:27.388762 - Started Query\n",
      "2025-05-03 22:17:33.635891 - Started Insertions\n",
      "2025-05-03 22:17:33.788919 - Committed record 50000\n",
      "2025-05-03 22:17:33.953448 - Committed record 100000\n",
      "2025-05-03 22:17:34.101648 - Committed record 150000\n",
      "2025-05-03 22:17:34.245273 - Committed record 200000\n",
      "2025-05-03 22:17:34.399075 - Committed record 250000\n",
      "2025-05-03 22:17:34.552598 - Committed record 300000\n",
      "2025-05-03 22:17:34.700152 - Committed record 350000\n",
      "2025-05-03 22:17:34.739140 - Committed record 365547\n",
      "2025-05-03 22:17:34.763664 - Started Query\n",
      "2025-05-03 22:17:41.002753 - Started Insertions\n",
      "2025-05-03 22:17:41.291184 - Committed record 100000\n",
      "2025-05-03 22:17:41.564744 - Committed record 200000\n",
      "2025-05-03 22:17:41.838319 - Committed record 300000\n",
      "2025-05-03 22:17:42.027361 - Committed record 365547\n"
     ]
    }
   ],
   "source": [
    "def run_8():\n",
    "    build_data_structures_8()\n",
    "    etl_team_8_sales()\n",
    "    etl_team_8_sales_daily()\n",
    "    etl_team_8_inventory()\n",
    "\n",
    "run_8()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfa0265-cb70-4fc1-ba89-b9253bc288b7",
   "metadata": {},
   "source": [
    "## 6. Generate Quarterly Snapshots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f296d7b4-8f68-4d8a-a1a1-6d810241bb35",
   "metadata": {},
   "source": [
    "Conceptual hurdles identified\n",
    "1. We need to do aggregation by quarter, which suggests a JOIN between the `inventory_daily` and the `date` tables\n",
    "2. We need the last inventory fact for each (Store, Date, Product) tuple  \n",
    "    &emsp; &emsp; for each tuple's `CasesOnHand` and `CasesPurchasedToDate`  \n",
    "    &emsp; &emsp; and these are non-additive.  \n",
    "    &emsp; &emsp; Some (Store, Date, Product) keys may not have an Inventory fact associated with them  \n",
    "    &emsp; &emsp; because they sold 0 and we need to LEFT-JOIN multiple tables  \n",
    "    &emsp; &emsp; and do a full table scan of each table at least once for each missing (Store, Date, Product) tuple.  \n",
    "4. We need to aggregate by quarter to generate the following:  \n",
    "    &emsp; &emsp; (1) Total costs and Counts sold by the store in the current quarter  \n",
    "    &emsp; &emsp; (2) Total costs and counts sold by the store YTD.  \n",
    "    &emsp; &emsp; Generating (2) involves a self-JOIN on already-aggregated data (which warrants the use of a CTE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73e62cc3-e201-4e0b-9605-e9b1656ab940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_date_mapping_tables():\n",
    "    db_8 = DB_HANDLES['DB_TEAM_8']\n",
    "\n",
    "    db_handles = [db_8]\n",
    "\n",
    "    start_date = date(2025, 1, 1)\n",
    "    end_date = date(2025, 6, 30)\n",
    "\n",
    "    current_date = start_date\n",
    "\n",
    "    sql_table_creation = '''\n",
    "                            CREATE TABLE date(\n",
    "                                date INT, \n",
    "                                quarter INT\n",
    "                            )\n",
    "                        '''\n",
    "    sql_insert = 'INSERT INTO date VALUES (?, ?)'\n",
    "    \n",
    "    for db in db_handles:\n",
    "        db.connect()\n",
    "        db.execute_sql('DROP TABLE IF EXISTS date')\n",
    "        db.execute_sql(sql_table_creation)\n",
    "\n",
    "    while(current_date <= end_date):\n",
    "        values_fmt_1 = (current_date.strftime('%Y-%m-%d'), ((current_date.month + 2)//3))\n",
    "\n",
    "        db_8.execute_sql_values(sql_insert, values_fmt_1)\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    for db in db_handles:\n",
    "        db.commit()\n",
    "        db.close()\n",
    "    \n",
    "build_date_mapping_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7ad59b-2b06-4109-9673-8c1250dc6af5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
